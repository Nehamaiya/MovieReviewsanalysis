{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import itertools\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from IPython.display import Image\n",
    "from math import ceil\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import SelectKBest , f_classif\n",
    "from tqdm import tqdm as t\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import eli5\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import textblob\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aclImdb', 'imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('C:/Users/Neha Maiya/reviews/aclImdb'))#link4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/Neha Maiya/reviews/aclImdb' #link4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posFiles = [x for x in os.listdir(PATH+\"/train/pos/\") if x.endswith(\".txt\")]\n",
    "negFiles = [x for x in os.listdir(PATH+\"/train/neg/\") if x.endswith(\".txt\")]#link 8\n",
    "\n",
    "# testFiles = [x for x in os.listdir(PATH+\"test/\") if x.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_Files= [x for x in os.listdir(PATH+\"/test/pos/\") if x.endswith(\".txt\")]\n",
    "test_neg_Files=[x for x in os.listdir(PATH+\"/test/neg/\") if x.endswith(\".txt\")]  #link 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_train=[]\n",
    "N_train=[]\n",
    "\n",
    "for nfile in negFiles:\n",
    "    with open(PATH+\"/train/neg/\"+nfile, encoding=\"utf-8\") as f:\n",
    "        N_train.append(f.read())\n",
    "for pfile in posFiles:\n",
    "    with open(PATH+\"/train/pos/\"+pfile, encoding=\"utf-8\") as f:\n",
    "        P_train.append(f.read())\n",
    "        #link 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_test=[]\n",
    "N_test=[]\n",
    "for ptestfile in test_pos_Files:\n",
    "    with open(PATH+\"/test/pos/\"+ptestfile, encoding=\"utf-8\") as f:\n",
    "        P_test.append(f.read())\n",
    "for ntestfile in test_neg_Files:\n",
    "    with open(PATH+\"/test/neg/\"+ntestfile, encoding=\"utf-8\") as f:\n",
    "        N_test.append(f.read())\n",
    "        #link 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_names = reviews_train.columns.tolist()\n",
    "# change_names[change_names.index('label')] = 'Sentiment'\n",
    "# reviews_train.columns = change_names\n",
    "# reviews_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21492</td>\n",
       "      <td>I have copy of this on VHS, I think they (The ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6844_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9488</td>\n",
       "      <td>After several extremely well ratings to the po...</td>\n",
       "      <td>1</td>\n",
       "      <td>7290_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16933</td>\n",
       "      <td>I still don't know why I forced myself to sit ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2740_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12604</td>\n",
       "      <td>Mt little sister and I are self-proclaimed hor...</td>\n",
       "      <td>-1</td>\n",
       "      <td>10094_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8222</td>\n",
       "      <td>I have personally seen many Disney movies in m...</td>\n",
       "      <td>1</td>\n",
       "      <td>6150_7.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  Label         file\n",
       "21492  I have copy of this on VHS, I think they (The ...     -1   6844_1.txt\n",
       "9488   After several extremely well ratings to the po...      1  7290_10.txt\n",
       "16933  I still don't know why I forced myself to sit ...     -1   2740_1.txt\n",
       "12604  Mt little sister and I are self-proclaimed hor...     -1  10094_1.txt\n",
       "8222   I have personally seen many Disney movies in m...      1   6150_7.txt"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train = pd.concat([\n",
    "    pd.DataFrame({\"review\":P_train, \"Label\":1, \"file\":posFiles}),\n",
    "    pd.DataFrame({\"review\":N_train, \"Label\":-1, \"file\":negFiles})\n",
    "], ignore_index=True).sample(frac=1, random_state=1)\n",
    "reviews_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_names_test = reviews_test.columns.tolist()\n",
    "# change_names_test[change_names_test.index('Sentiment')] = 'Sentiment_Test'\n",
    "# reviews_test.columns = change_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21492</td>\n",
       "      <td>A movie theater with a bad history of past gru...</td>\n",
       "      <td>-2</td>\n",
       "      <td>6844_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9488</td>\n",
       "      <td>\"Here On Earth\" is a surprising beautiful roma...</td>\n",
       "      <td>2</td>\n",
       "      <td>7290_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16933</td>\n",
       "      <td>I just watched Descent. Gawds what an awful mo...</td>\n",
       "      <td>-2</td>\n",
       "      <td>2740_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12604</td>\n",
       "      <td>In a nutshell the movie is about a gang war in...</td>\n",
       "      <td>-2</td>\n",
       "      <td>10094_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8222</td>\n",
       "      <td>Instead of watching the recycled history of \"P...</td>\n",
       "      <td>2</td>\n",
       "      <td>6150_7.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  Label         file\n",
       "21492  A movie theater with a bad history of past gru...     -2   6844_2.txt\n",
       "9488   \"Here On Earth\" is a surprising beautiful roma...      2  7290_10.txt\n",
       "16933  I just watched Descent. Gawds what an awful mo...     -2   2740_3.txt\n",
       "12604  In a nutshell the movie is about a gang war in...     -2  10094_4.txt\n",
       "8222   Instead of watching the recycled history of \"P...      2   6150_7.txt"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    reviews_test = pd.concat([\n",
    "    pd.DataFrame({\"review\":P_test, \"Label\":2, \"file\":test_pos_Files}),\n",
    "    pd.DataFrame({\"review\":N_test, \"Label\":-2,\"file\":test_neg_Files})\n",
    "], ignore_index=True).sample(frac=1, random_state=1)\n",
    "reviews_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21492</td>\n",
       "      <td>A movie theater with a bad history of past gru...</td>\n",
       "      <td>-2</td>\n",
       "      <td>6844_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9488</td>\n",
       "      <td>\"Here On Earth\" is a surprising beautiful roma...</td>\n",
       "      <td>2</td>\n",
       "      <td>7290_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16933</td>\n",
       "      <td>I just watched Descent. Gawds what an awful mo...</td>\n",
       "      <td>-2</td>\n",
       "      <td>2740_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12604</td>\n",
       "      <td>In a nutshell the movie is about a gang war in...</td>\n",
       "      <td>-2</td>\n",
       "      <td>10094_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8222</td>\n",
       "      <td>Instead of watching the recycled history of \"P...</td>\n",
       "      <td>2</td>\n",
       "      <td>6150_7.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110</td>\n",
       "      <td>This is an incredibly compelling story, told w...</td>\n",
       "      <td>2</td>\n",
       "      <td>6950_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21196</td>\n",
       "      <td>I like underdogs. So, 12 years after having fi...</td>\n",
       "      <td>-2</td>\n",
       "      <td>6578_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17193</td>\n",
       "      <td>Okay, so I'm Singaporean and I would like to s...</td>\n",
       "      <td>-2</td>\n",
       "      <td>2975_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23846</td>\n",
       "      <td>**** MILD SPOILERS _ BUT YOU PROBABLY KNOW THE...</td>\n",
       "      <td>-2</td>\n",
       "      <td>8963_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10415</td>\n",
       "      <td>Bedrooms and Hallways gives its audience a loo...</td>\n",
       "      <td>2</td>\n",
       "      <td>8124_8.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  Label         file\n",
       "21492  A movie theater with a bad history of past gru...     -2   6844_2.txt\n",
       "9488   \"Here On Earth\" is a surprising beautiful roma...      2  7290_10.txt\n",
       "16933  I just watched Descent. Gawds what an awful mo...     -2   2740_3.txt\n",
       "12604  In a nutshell the movie is about a gang war in...     -2  10094_4.txt\n",
       "8222   Instead of watching the recycled history of \"P...      2   6150_7.txt\n",
       "9110   This is an incredibly compelling story, told w...      2  6950_10.txt\n",
       "21196  I like underdogs. So, 12 years after having fi...     -2   6578_4.txt\n",
       "17193  Okay, so I'm Singaporean and I would like to s...     -2   2975_2.txt\n",
       "23846  **** MILD SPOILERS _ BUT YOU PROBABLY KNOW THE...     -2   8963_4.txt\n",
       "10415  Bedrooms and Hallways gives its audience a loo...      2   8124_8.txt"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 21492 to 235\n",
      "Data columns (total 3 columns):\n",
      "review    25000 non-null object\n",
      "Label     25000 non-null int64\n",
      "file      25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 781.2+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label\n",
       "count  25000.00000\n",
       "mean       0.00000\n",
       "std        1.00002\n",
       "min       -1.00000\n",
       "25%       -1.00000\n",
       "50%        0.00000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    12500\n",
       " 1    12500\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b6a79ea848>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(6,5)})\n",
    "sns.countplot(reviews_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#character count link 4\n",
    "reviews_train[reviews_train['Label']==1]['review'].apply(lambda y: np.log1p(len(y))).hist(alpha=0.5, color='blue', label='Positive')\n",
    "reviews_train[reviews_train['Label']==-1]['review'].apply(lambda y: np.log1p(len(y))).hist(alpha=0.5, color='yellow', label='Negative')\n",
    "plt.title('Character count for reviews')\n",
    "plt.legend();\n",
    "# alpha is for the darkness of color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2,  2], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# dataset.review = dataset.review.apply(lambda r: BeautifulSoup(r, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.lang.en import English\n",
    "en_core_web_sm.load()\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import html as ihtml\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    After several extremely well ratings to the po...\n",
       "Label                                                     1\n",
       "file                                            7290_10.txt\n",
       "Name: 9488, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmvhtmltags(text):\n",
    "    remreg = re.compile('<.*?>')\n",
    "    cleartext = re.sub(remreg, '', text)\n",
    "    return text\n",
    "# Function to remove URLs starting with https/http \n",
    "def remove_urls (vTEXT):\n",
    "    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "    return(vTEXT)\n",
    "\n",
    "def rmvspclcharacter(text):\n",
    "\n",
    "    #convert to lowercase and ignore special charcter\n",
    "    clearspcl = re.sub(r'[^A-Za-z0-9\\s.]', r'', str(text).lower())\n",
    "    clearspcl = re.sub(r'\\n', r' ', text)\n",
    "    \n",
    "    \n",
    "    clearspcl = \" \".join([word for word in text.split() if word not in stopWords])\n",
    "    \n",
    "#     clearspcl\n",
    "\n",
    "\n",
    "#     print(' '.join(stemming_texts))\n",
    "    return text\n",
    "def stemming_text(text):\n",
    "    stemmed_words = [snowballstemmer.stem(word) for word in text.split()]\n",
    "    return('  '.join(stemmed_words))\n",
    "    \n",
    "#lemmantize\n",
    "def lemmatize_words(text):\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, 'v') for word in text.split()]\n",
    "    return('  '.join(lemmatized_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_list(l):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in l if x not in ulist]\n",
    "    return ulist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataprocessing(x):\n",
    "    x = rmvhtmltags(x)\n",
    "    x = remove_urls(x)\n",
    "\n",
    "    x = x.lower()\n",
    "    x = rmvspclcharacter(x)\n",
    "#     \n",
    "    x = remove_stopwords(x)\n",
    "    x = strip_punctuation(x)\n",
    "    x = strip_multiple_whitespaces(x)\n",
    "    x = stemming_text(x)\n",
    "    #x = lemmatize_words(x)\n",
    "    x=' '.join([re.sub(r'\\d+', '',i) for i in word_tokenize(x)])\n",
    "#     x = stemming(x)\n",
    "#    x = ' '.join(unique_list(x.split()))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train['review'] = reviews_train['review'].map(lambda x: dataprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'critic acclaim psycholog thriller base true event gabriel robin william celebr writer late night talk host captiv harrow stori young listen adopt mother toni collett troubl question aris boy s stori howev gabriel find drawn widen mysteri hide dead secret accord film s offici synopsi br br you stop read comment watch film now br br the how lose leg end ms collett plan new life chop off sent delet scene land it s overkil true natur physic mental ailment obvious time mr william return new york possibl blind question revel certain highway video tape scene film benefit re edit director s cut br br william bobbi cannaval as jess don t seem initi believ coupl scene establish relationship help set stage otherwis cast exemplari william offer except strong character gay imperson sandra oh as anna joe morton as ash rori culkin pete logand perfect br br best all collett s donna belong creepi hall fame ms oh correct say collett be you know like guy psycho year organ give act award reach women slighter dispers role certain notic collett award consider good and director patrick stettner definit evok hitchcock make get sandwich vend machin suspens br br final writer stettner armistead maupin terri anderson deserv gratitud flight attend everywher br br night listen    patrick stettner robin william toni collett sandra oh rori culkin'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train['review'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_train['review'] = reviews_train['review'].map(lambda x: stemming_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "countvect = vectorizer.fit_transform(reviews_train['review'])\n",
    "countvect = countvect.tocsc()  \n",
    "countl = (reviews_train['Label'] == 1).values.astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x49412 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2283538 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21492   -1\n",
       "9488     1\n",
       "16933   -1\n",
       "12604   -1\n",
       "8222     1\n",
       "        ..\n",
       "10955    1\n",
       "17289   -1\n",
       "5192     1\n",
       "12172    1\n",
       "235      1\n",
       "Name: Label, Length: 25000, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_c = reviews_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (9042, 0)\t1\n",
      "  (10021, 0)\t1\n",
      "  (13626, 0)\t1\n",
      "  (14396, 0)\t1\n",
      "  (21186, 0)\t1\n",
      "  (1222, 1)\t1\n",
      "  (7419, 1)\t4\n",
      "  (9042, 1)\t1\n",
      "  (18775, 1)\t1\n",
      "  (21050, 1)\t1\n",
      "  (24959, 1)\t1\n",
      "  (5940, 2)\t1\n",
      "  (20169, 3)\t1\n",
      "  (241, 4)\t1\n",
      "  (8459, 5)\t1\n",
      "  (331, 6)\t1\n",
      "  (6602, 7)\t1\n",
      "  (20169, 8)\t1\n",
      "  (3748, 9)\t1\n",
      "  (14536, 9)\t1\n",
      "  (18929, 9)\t1\n",
      "  (23454, 9)\t1\n",
      "  (17572, 10)\t1\n",
      "  (3110, 11)\t1\n",
      "  (3588, 12)\t1\n",
      "  :\t:\n",
      "  (20070, 49398)\t1\n",
      "  (7387, 49399)\t1\n",
      "  (17707, 49399)\t1\n",
      "  (24442, 49400)\t1\n",
      "  (2073, 49401)\t1\n",
      "  (3193, 49401)\t1\n",
      "  (9210, 49401)\t1\n",
      "  (13301, 49401)\t1\n",
      "  (22011, 49401)\t1\n",
      "  (22630, 49401)\t1\n",
      "  (18648, 49402)\t2\n",
      "  (20500, 49402)\t1\n",
      "  (4137, 49403)\t2\n",
      "  (4454, 49403)\t1\n",
      "  (10411, 49404)\t1\n",
      "  (9124, 49405)\t1\n",
      "  (22204, 49406)\t1\n",
      "  (10233, 49407)\t1\n",
      "  (410, 49408)\t1\n",
      "  (21691, 49409)\t1\n",
      "  (1600, 49410)\t1\n",
      "  (14884, 49410)\t1\n",
      "  (18699, 49410)\t1\n",
      "  (20279, 49410)\t1\n",
      "  (7074, 49411)\t1 [0 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(countvect,countl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaaaaah',\n",
       " 'aaaaah',\n",
       " 'aaaaatch',\n",
       " 'aaaahhhhhhh',\n",
       " 'aaaand',\n",
       " 'aaaarrgh',\n",
       " 'aaah',\n",
       " 'aaargh',\n",
       " 'aaaugh',\n",
       " 'aaawwwwnnn',\n",
       " 'aachen',\n",
       " 'aada',\n",
       " 'aadha',\n",
       " 'aag',\n",
       " 'aaghh',\n",
       " 'aah',\n",
       " 'aahhh',\n",
       " 'aaip',\n",
       " 'aaja',\n",
       " 'aakash',\n",
       " 'aaker',\n",
       " 'aakrosh',\n",
       " 'aaliyah',\n",
       " 'aam',\n",
       " 'aamir',\n",
       " 'aan',\n",
       " 'aankh',\n",
       " 'aankhen',\n",
       " 'aap',\n",
       " 'aapk',\n",
       " 'aapkey',\n",
       " 'aardman',\n",
       " 'aardvark',\n",
       " 'aargh',\n",
       " 'aaron',\n",
       " 'aarp',\n",
       " 'aarrrgh',\n",
       " 'aatish',\n",
       " 'aauugghh',\n",
       " 'aavjo',\n",
       " 'aaww',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'aback',\n",
       " 'abadi',\n",
       " 'abahi',\n",
       " 'abanaz',\n",
       " 'abandon',\n",
       " 'abank',\n",
       " 'abash',\n",
       " 'abashidz',\n",
       " 'abat',\n",
       " 'abattoir',\n",
       " 'abba',\n",
       " 'abbad',\n",
       " 'abbasi',\n",
       " 'abbey',\n",
       " 'abbi',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abbrevi',\n",
       " 'abbu',\n",
       " 'abc',\n",
       " 'abcd',\n",
       " 'abdic',\n",
       " 'abdomen',\n",
       " 'abdomin',\n",
       " 'abdu',\n",
       " 'abduct',\n",
       " 'abducte',\n",
       " 'abductor',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'abercrombi',\n",
       " 'abernathi',\n",
       " 'aberr',\n",
       " 'aberystwyth',\n",
       " 'abet',\n",
       " 'abey',\n",
       " 'abgail',\n",
       " 'abhay',\n",
       " 'abhi',\n",
       " 'abhijeet',\n",
       " 'abhimaan',\n",
       " 'abhisheh',\n",
       " 'abhishek',\n",
       " 'abhor',\n",
       " 'abhorr',\n",
       " 'abi',\n",
       " 'abid',\n",
       " 'abigail',\n",
       " 'abigil',\n",
       " 'abil',\n",
       " 'abilityof',\n",
       " 'abishai',\n",
       " 'abishek',\n",
       " 'abject',\n",
       " 'abkani',\n",
       " 'abl',\n",
       " 'ablaz',\n",
       " 'abli',\n",
       " 'abm',\n",
       " 'abner',\n",
       " 'abnorm',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abod',\n",
       " 'abolish',\n",
       " 'abolit',\n",
       " 'abolition',\n",
       " 'abolitionist',\n",
       " 'abomin',\n",
       " 'abominib',\n",
       " 'aboooot',\n",
       " 'aborigin',\n",
       " 'aborigini',\n",
       " 'aborigon',\n",
       " 'abort',\n",
       " 'abortionist',\n",
       " 'abott',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'aboutagir',\n",
       " 'abov',\n",
       " 'abovement',\n",
       " 'abr',\n",
       " 'abracadabrantesqu',\n",
       " 'abraham',\n",
       " 'abrahm',\n",
       " 'abram',\n",
       " 'abras',\n",
       " 'abrazo',\n",
       " 'abreast',\n",
       " 'abridg',\n",
       " 'abril',\n",
       " 'abroad',\n",
       " 'abromowitz',\n",
       " 'abrupt',\n",
       " 'absalom',\n",
       " 'abscess',\n",
       " 'abscond',\n",
       " 'absenc',\n",
       " 'absens',\n",
       " 'absent',\n",
       " 'absente',\n",
       " 'absentmind',\n",
       " 'abskani',\n",
       " 'absolom',\n",
       " 'absolut',\n",
       " 'absolutelli',\n",
       " 'absolutey',\n",
       " 'absolutl',\n",
       " 'absolutley',\n",
       " 'absolv',\n",
       " 'absorb',\n",
       " 'absorpt',\n",
       " 'absoul',\n",
       " 'absoutley',\n",
       " 'abstain',\n",
       " 'abstin',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abuelita',\n",
       " 'abunch',\n",
       " 'abund',\n",
       " 'abus',\n",
       " 'abut',\n",
       " 'abuzz',\n",
       " 'abvious',\n",
       " 'abydo',\n",
       " 'abysm',\n",
       " 'abyss',\n",
       " 'abyssm',\n",
       " 'abysym',\n",
       " 'ac',\n",
       " 'acadami',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'academia',\n",
       " 'acadmey',\n",
       " 'acapella',\n",
       " 'acapulco',\n",
       " 'acc',\n",
       " 'accapella',\n",
       " 'acced',\n",
       " 'acceler',\n",
       " 'accent',\n",
       " 'accentu',\n",
       " 'accept',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accessor',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accidente',\n",
       " 'acclaim',\n",
       " 'acclam',\n",
       " 'acclim',\n",
       " 'accolad',\n",
       " 'accommod',\n",
       " 'accompagni',\n",
       " 'accompani',\n",
       " 'accomplic',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'accordian',\n",
       " 'accordion',\n",
       " 'accorsi',\n",
       " 'accost',\n",
       " 'account',\n",
       " 'accouter',\n",
       " 'accredit',\n",
       " 'accru',\n",
       " 'accrut',\n",
       " 'acct',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'accurs',\n",
       " 'accus',\n",
       " 'accusatori',\n",
       " 'accustom',\n",
       " 'acd',\n",
       " 'ace',\n",
       " 'acedemi',\n",
       " 'acedmi',\n",
       " 'acerb',\n",
       " 'acetylen',\n",
       " 'ach',\n",
       " 'achad',\n",
       " 'achala',\n",
       " 'acharya',\n",
       " 'achcha',\n",
       " 'acheaolog',\n",
       " 'acheiv',\n",
       " 'achero',\n",
       " 'achiev',\n",
       " 'achil',\n",
       " 'achill',\n",
       " 'achillea',\n",
       " 'achiv',\n",
       " 'achra',\n",
       " 'achterbusch',\n",
       " 'acid',\n",
       " 'acin',\n",
       " 'aciton',\n",
       " 'ack',\n",
       " 'acker',\n",
       " 'ackerman',\n",
       " 'ackland',\n",
       " 'acknowledg',\n",
       " 'ackroyd',\n",
       " 'acl',\n",
       " 'aclear',\n",
       " 'aclu',\n",
       " 'acm',\n",
       " 'acmetropoli',\n",
       " 'acn',\n",
       " 'acolyt',\n",
       " 'acompl',\n",
       " 'acorn',\n",
       " 'acosta',\n",
       " 'acoust',\n",
       " 'acp',\n",
       " 'acquaint',\n",
       " 'acquaintac',\n",
       " 'acquart',\n",
       " 'acquiesc',\n",
       " 'acquir',\n",
       " 'acquisit',\n",
       " 'acquit',\n",
       " 'acquitan',\n",
       " 'acquitt',\n",
       " 'acr',\n",
       " 'acrid',\n",
       " 'acrimoni',\n",
       " 'acrobat',\n",
       " 'acronym',\n",
       " 'acropoli',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actal',\n",
       " 'actelon',\n",
       " 'actess',\n",
       " 'acteur',\n",
       " 'actin',\n",
       " 'actingjob',\n",
       " 'actingwis',\n",
       " 'actio',\n",
       " 'action',\n",
       " 'actiona',\n",
       " 'actionless',\n",
       " 'actionmovi',\n",
       " 'actionpack',\n",
       " 'actionscen',\n",
       " 'activ',\n",
       " 'activest',\n",
       " 'activis',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actra',\n",
       " 'actreesess',\n",
       " 'actress',\n",
       " 'actriss',\n",
       " 'actual',\n",
       " 'actuali',\n",
       " 'actuelli',\n",
       " 'actullli',\n",
       " 'actur',\n",
       " 'acual',\n",
       " 'acuiti',\n",
       " 'acumen',\n",
       " 'acupat',\n",
       " 'acur',\n",
       " 'acus',\n",
       " 'acut',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adabt',\n",
       " 'adachi',\n",
       " 'adag',\n",
       " 'adagio',\n",
       " 'adair',\n",
       " 'adalbert',\n",
       " 'adam',\n",
       " 'adama',\n",
       " 'adamantium',\n",
       " 'adamo',\n",
       " 'adamson',\n",
       " 'adapt',\n",
       " 'adaptaion',\n",
       " 'adaptor',\n",
       " 'adcox',\n",
       " 'add',\n",
       " 'addam',\n",
       " 'addario',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'addi',\n",
       " 'addict',\n",
       " 'addio',\n",
       " 'addison',\n",
       " 'addit',\n",
       " 'addl',\n",
       " 'addon',\n",
       " 'address',\n",
       " 'adel',\n",
       " 'adela',\n",
       " 'adelad',\n",
       " 'adelaid',\n",
       " 'adelin',\n",
       " 'adell',\n",
       " 'ademir',\n",
       " 'aden',\n",
       " 'adenin',\n",
       " 'adenoid',\n",
       " 'adept',\n",
       " 'adequ',\n",
       " 'adequate',\n",
       " 'adgth',\n",
       " 'adhd',\n",
       " 'adher',\n",
       " 'adhes',\n",
       " 'adhura',\n",
       " 'adi',\n",
       " 'adibah',\n",
       " 'adien',\n",
       " 'adieu',\n",
       " 'adio',\n",
       " 'aditiya',\n",
       " 'aditya',\n",
       " 'adj',\n",
       " 'adjac',\n",
       " 'adjani',\n",
       " 'adject',\n",
       " 'adjoin',\n",
       " 'adjourn',\n",
       " 'adjunct',\n",
       " 'adjurduboi',\n",
       " 'adjust',\n",
       " 'adjustin',\n",
       " 'adjut',\n",
       " 'adkin',\n",
       " 'adl',\n",
       " 'adlai',\n",
       " 'adler',\n",
       " 'adm',\n",
       " 'adma',\n",
       " 'adman',\n",
       " 'admar',\n",
       " 'administ',\n",
       " 'administr',\n",
       " 'adminsitr',\n",
       " 'admir',\n",
       " 'admira',\n",
       " 'admiralti',\n",
       " 'admire',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'admitt',\n",
       " 'admittad',\n",
       " 'admixtur',\n",
       " 'admonish',\n",
       " 'admonit',\n",
       " 'adnan',\n",
       " 'adnausem',\n",
       " 'ado',\n",
       " 'adob',\n",
       " 'adolesc',\n",
       " 'adolf',\n",
       " 'adolfo',\n",
       " 'adolph',\n",
       " 'adon',\n",
       " 'adoni',\n",
       " 'adopt',\n",
       " 'adopte',\n",
       " 'ador',\n",
       " 'adorbl',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adotp',\n",
       " 'adr',\n",
       " 'adrenalin',\n",
       " 'adreno',\n",
       " 'adreon',\n",
       " 'adrian',\n",
       " 'adriana',\n",
       " 'adriann',\n",
       " 'adriano',\n",
       " 'adriat',\n",
       " 'adrien',\n",
       " 'adrienn',\n",
       " 'adriensen',\n",
       " 'adrift',\n",
       " 'adroit',\n",
       " 'adt',\n",
       " 'adul',\n",
       " 'adulhood',\n",
       " 'adult',\n",
       " 'adulter',\n",
       " 'adulteress',\n",
       " 'adulteri',\n",
       " 'adulthood',\n",
       " 'adultri',\n",
       " 'adv',\n",
       " 'advan',\n",
       " 'advanc',\n",
       " 'advani',\n",
       " 'advantag',\n",
       " 'advent',\n",
       " 'adventist',\n",
       " 'adventur',\n",
       " 'adventuresom',\n",
       " 'advers',\n",
       " 'adversari',\n",
       " 'advert',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advisor',\n",
       " 'advisori',\n",
       " 'advoc',\n",
       " 'advocaci',\n",
       " 'adl',\n",
       " 'ae',\n",
       " 'aegean',\n",
       " 'aegert',\n",
       " 'aeneid',\n",
       " 'aeon',\n",
       " 'aerial',\n",
       " 'aero',\n",
       " 'aerob',\n",
       " 'aerobicid',\n",
       " 'aerodynam',\n",
       " 'aeronaut',\n",
       " 'aeroplan',\n",
       " 'aerosol',\n",
       " 'aesir',\n",
       " 'aesop',\n",
       " 'aestheic',\n",
       " 'aesthet',\n",
       " 'aesthetic',\n",
       " 'aetheist',\n",
       " 'aetheri',\n",
       " 'af',\n",
       " 'afar',\n",
       " 'afb',\n",
       " 'afer',\n",
       " 'afest',\n",
       " 'afew',\n",
       " 'aff',\n",
       " 'affabl',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affectionn',\n",
       " 'affectt',\n",
       " 'afficinado',\n",
       " 'afficionado',\n",
       " 'affili',\n",
       " 'affin',\n",
       " 'affinit',\n",
       " 'affirm',\n",
       " 'affix',\n",
       " 'affleck',\n",
       " 'afflect',\n",
       " 'afflict',\n",
       " 'affluenc',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affront',\n",
       " 'affter',\n",
       " 'afgahnistan',\n",
       " 'afgan',\n",
       " 'afgani',\n",
       " 'afganistan',\n",
       " 'afghan',\n",
       " 'afghanastan',\n",
       " 'afghani',\n",
       " 'afghanistan',\n",
       " 'afi',\n",
       " 'afican',\n",
       " 'aficionado',\n",
       " 'afield',\n",
       " 'afilm',\n",
       " 'afirm',\n",
       " 'afl',\n",
       " 'aflac',\n",
       " 'aflam',\n",
       " 'afleck',\n",
       " 'afloat',\n",
       " 'afm',\n",
       " 'afonya',\n",
       " 'afoot',\n",
       " 'afor',\n",
       " 'aforement',\n",
       " 'aforesaid',\n",
       " 'aforment',\n",
       " 'afortun',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'afresh',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afrika',\n",
       " 'afrikaan',\n",
       " 'afrikan',\n",
       " 'afrikanerdom',\n",
       " 'afro',\n",
       " 'afroamerican',\n",
       " 'afrovideo',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afteral',\n",
       " 'afterbirth',\n",
       " 'aftereffect',\n",
       " 'afterglow',\n",
       " 'afterl',\n",
       " 'afterlif',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterschool',\n",
       " 'aftershock',\n",
       " 'afterstori',\n",
       " 'aftertast',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwhil',\n",
       " 'afterword',\n",
       " 'afterworld',\n",
       " 'aftra',\n",
       " 'afv',\n",
       " 'ag',\n",
       " 'aga',\n",
       " 'agaaaain',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agamemnon',\n",
       " 'agap',\n",
       " 'agar',\n",
       " 'agatha',\n",
       " 'agbayani',\n",
       " 'age',\n",
       " 'ageless',\n",
       " 'agenc',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agentin',\n",
       " 'ager',\n",
       " 'agey',\n",
       " 'aggelopoulo',\n",
       " 'aggh',\n",
       " 'aggi',\n",
       " 'aggrand',\n",
       " 'aggrandiz',\n",
       " 'aggrav',\n",
       " 'aggres',\n",
       " 'aggress',\n",
       " 'aggressor',\n",
       " 'aggriev',\n",
       " 'aggriv',\n",
       " 'agha',\n",
       " 'aghast',\n",
       " 'aghhh',\n",
       " 'aghnaistan',\n",
       " 'agi',\n",
       " 'agian',\n",
       " 'agil',\n",
       " 'agin',\n",
       " 'agit',\n",
       " 'agito',\n",
       " 'agitprop',\n",
       " 'agla',\n",
       " 'agless',\n",
       " 'agn',\n",
       " 'agnew',\n",
       " 'agnieszka',\n",
       " 'agniezska',\n",
       " 'agnisakshi',\n",
       " 'agnost',\n",
       " 'agnostic',\n",
       " 'agnus',\n",
       " 'agn',\n",
       " 'ago',\n",
       " 'agon',\n",
       " 'agoni',\n",
       " 'agonia',\n",
       " 'agonis',\n",
       " 'agoraphob',\n",
       " 'agostino',\n",
       " 'agrama',\n",
       " 'agrandiz',\n",
       " 'agrarian',\n",
       " 'agraw',\n",
       " 'agre',\n",
       " 'agreeabl',\n",
       " 'agreement',\n",
       " 'agricultur',\n",
       " 'agro',\n",
       " 'agrument',\n",
       " 'aguila',\n",
       " 'aguilera',\n",
       " 'aguirr',\n",
       " 'agusti',\n",
       " 'agustin',\n",
       " 'agust',\n",
       " 'agutt',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahab',\n",
       " 'ahah',\n",
       " 'ahahahah',\n",
       " 'ahahahahahaaaaa',\n",
       " 'ahahahahahhahahahahahahahahahhahahahahahahah',\n",
       " 'ahahhahahaha',\n",
       " 'ahamad',\n",
       " 'ahamd',\n",
       " 'ahead',\n",
       " 'aheheh',\n",
       " 'ahem',\n",
       " 'ahet',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahhhhhh',\n",
       " 'ahhhhhhhhh',\n",
       " 'ahista',\n",
       " 'ahistor',\n",
       " 'ahlan',\n",
       " 'ahlberg',\n",
       " 'ahlstedt',\n",
       " 'ahm',\n",
       " 'ahmad',\n",
       " 'ahmadinejad',\n",
       " 'ahn',\n",
       " 'ahold',\n",
       " 'ahoy',\n",
       " 'ahu',\n",
       " 'ai',\n",
       " 'aicha',\n",
       " 'aicn',\n",
       " 'aid',\n",
       " 'aida',\n",
       " 'aidan',\n",
       " 'aiden',\n",
       " 'aidsssss',\n",
       " 'aiello',\n",
       " 'aielo',\n",
       " 'aiieeee',\n",
       " 'aiken',\n",
       " 'aikido',\n",
       " 'aikidoist',\n",
       " 'ail',\n",
       " 'aileen',\n",
       " 'ailment',\n",
       " 'ailtan',\n",
       " 'ailton',\n",
       " 'aim',\n",
       " 'aimanov',\n",
       " 'aimant',\n",
       " 'aime',\n",
       " 'aimless',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'ainc',\n",
       " 'ainley',\n",
       " 'ainsworth',\n",
       " 'aint',\n",
       " 'aintri',\n",
       " 'aip',\n",
       " 'air',\n",
       " 'airbag',\n",
       " 'airbal',\n",
       " 'airborn',\n",
       " 'airbrush',\n",
       " 'aircraft',\n",
       " 'aircrew',\n",
       " 'airdat',\n",
       " 'airfield',\n",
       " 'airfix',\n",
       " 'airforc',\n",
       " 'airhead',\n",
       " 'airheaded',\n",
       " 'airhostess',\n",
       " 'airi',\n",
       " 'airial',\n",
       " 'airless',\n",
       " 'airlift',\n",
       " 'airlin',\n",
       " 'airlock',\n",
       " 'airman',\n",
       " 'airmen',\n",
       " 'airphon',\n",
       " 'airplan',\n",
       " 'airplay',\n",
       " 'airport',\n",
       " 'airship',\n",
       " 'airsick',\n",
       " 'airsoft',\n",
       " 'airspac',\n",
       " 'airspe',\n",
       " 'airstrik',\n",
       " 'airstrip',\n",
       " 'airtight',\n",
       " 'airtim',\n",
       " 'airwav',\n",
       " 'airway',\n",
       " 'airwolf',\n",
       " 'aish',\n",
       " 'aishu',\n",
       " 'aishwarya',\n",
       " 'aisl',\n",
       " 'aislinn',\n",
       " 'aissa',\n",
       " 'ait',\n",
       " 'aitd',\n",
       " 'aito',\n",
       " 'aj',\n",
       " 'aja',\n",
       " 'ajax',\n",
       " 'ajay',\n",
       " 'ajeeb',\n",
       " 'aji',\n",
       " 'ajikko',\n",
       " 'ajnab',\n",
       " 'ajnabi',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akai',\n",
       " 'akan',\n",
       " 'akbar',\n",
       " 'akcent',\n",
       " 'akeem',\n",
       " 'akelli',\n",
       " 'akerston',\n",
       " 'akhra',\n",
       " 'akhtar',\n",
       " 'aki',\n",
       " 'akim',\n",
       " 'akimbo',\n",
       " 'akimoto',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'akiva',\n",
       " 'akiyama',\n",
       " 'akkaya',\n",
       " 'akki',\n",
       " 'akm',\n",
       " 'aknowledg',\n",
       " 'akosua',\n",
       " 'akra',\n",
       " 'akria',\n",
       " 'akroyd',\n",
       " 'akshay',\n",
       " 'akshaya',\n",
       " 'akshey',\n",
       " 'akst',\n",
       " 'akt',\n",
       " 'aku',\n",
       " 'akuzi',\n",
       " 'akward',\n",
       " 'akyroyd',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alabast',\n",
       " 'alacr',\n",
       " 'aladdin',\n",
       " 'aladin',\n",
       " 'alahani',\n",
       " 'alain',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alana',\n",
       " 'alani',\n",
       " 'alanni',\n",
       " 'alanrickmaniac',\n",
       " 'alanti',\n",
       " 'alar',\n",
       " 'alarik',\n",
       " 'alarm',\n",
       " 'alarmist',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alaskey',\n",
       " 'alastair',\n",
       " 'alatri',\n",
       " 'alba',\n",
       " 'albacor',\n",
       " 'albaladejo',\n",
       " 'alban',\n",
       " 'albani',\n",
       " 'albania',\n",
       " 'albanian',\n",
       " 'albany',\n",
       " 'albatross',\n",
       " 'albeit',\n",
       " 'albeniz',\n",
       " 'alberni',\n",
       " 'alberson',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertin',\n",
       " 'albertini',\n",
       " 'alberto',\n",
       " 'albertson',\n",
       " 'albiet',\n",
       " 'albin',\n",
       " 'albino',\n",
       " 'albinoni',\n",
       " 'albizo',\n",
       " 'albizu',\n",
       " 'albot',\n",
       " 'albright',\n",
       " 'album',\n",
       " 'albuquerqu',\n",
       " 'albniz',\n",
       " 'alc',\n",
       " 'alcain',\n",
       " 'alcantara',\n",
       " 'alcatraz',\n",
       " 'alchem',\n",
       " 'alchemi',\n",
       " 'alchemist',\n",
       " 'alchohol',\n",
       " 'alcid',\n",
       " 'alcohol',\n",
       " 'alcott',\n",
       " 'alda',\n",
       " 'aldar',\n",
       " 'alden',\n",
       " 'alderich',\n",
       " 'alderson',\n",
       " 'aldiss',\n",
       " 'aldo',\n",
       " 'aldofo',\n",
       " 'aldolpho',\n",
       " 'aldonova',\n",
       " 'aldrich',\n",
       " 'aldridg',\n",
       " 'aldrin',\n",
       " 'aldwych',\n",
       " 'ale',\n",
       " 'alec',\n",
       " 'alecia',\n",
       " 'aleck',\n",
       " 'alecki',\n",
       " 'alegria',\n",
       " 'alein',\n",
       " 'aleisa',\n",
       " 'aleist',\n",
       " 'alejandra',\n",
       " 'alejandro',\n",
       " 'alejo',\n",
       " 'aleko',\n",
       " 'aleksandar',\n",
       " 'aleksandr',\n",
       " 'aleksei',\n",
       " 'aleopath',\n",
       " 'alert',\n",
       " 'alesia',\n",
       " 'alessandra',\n",
       " 'alessandro',\n",
       " 'alessio',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexanad',\n",
       " 'alexand',\n",
       " 'alexanderplatz',\n",
       " 'alexandr',\n",
       " 'alexandra',\n",
       " 'alexandria',\n",
       " 'alexei',\n",
       " 'alexej',\n",
       " 'alexi',\n",
       " 'alexia',\n",
       " 'alexio',\n",
       " 'alexondra',\n",
       " 'aleya',\n",
       " 'alf',\n",
       " 'alfi',\n",
       " 'alfio',\n",
       " 'alfons',\n",
       " 'alfonso',\n",
       " 'alfr',\n",
       " 'alfredo',\n",
       " 'alfri',\n",
       " 'alfven',\n",
       " 'alga',\n",
       " 'alger',\n",
       " 'algeria',\n",
       " 'algerian',\n",
       " 'algernon',\n",
       " 'algi',\n",
       " 'algier',\n",
       " 'algorithm',\n",
       " 'algrant',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'alias',\n",
       " 'alibi',\n",
       " 'alic',\n",
       " 'alicia',\n",
       " 'aliciann',\n",
       " 'alida',\n",
       " 'alien',\n",
       " 'alien',\n",
       " 'alight',\n",
       " 'align',\n",
       " 'alija',\n",
       " 'alik',\n",
       " 'alike',\n",
       " 'alimoni',\n",
       " 'alin',\n",
       " 'alisan',\n",
       " 'alisand',\n",
       " 'alisha',\n",
       " 'aliso',\n",
       " 'alison',\n",
       " 'alissia',\n",
       " 'alistair',\n",
       " 'alistar',\n",
       " 'alita',\n",
       " 'aliti',\n",
       " 'alittl',\n",
       " 'aliv',\n",
       " 'alix',\n",
       " 'alka',\n",
       " 'alki',\n",
       " 'all',\n",
       " 'alla',\n",
       " 'alladin',\n",
       " 'allah',\n",
       " 'allahabad',\n",
       " 'allan',\n",
       " 'allanc',\n",
       " 'allay',\n",
       " 'allayli',\n",
       " 'alldredg',\n",
       " 'alleb',\n",
       " 'alledg',\n",
       " 'alleg',\n",
       " 'allegi',\n",
       " 'allegor',\n",
       " 'allegori',\n",
       " 'allen',\n",
       " 'allend',\n",
       " 'allerg',\n",
       " 'allergi',\n",
       " 'allevi',\n",
       " 'alley',\n",
       " ...]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_label = reviews_train['Label'].tolist()\n",
    "x_train_review = reviews_train['review'].tolist()\n",
    "\n",
    "y_test_label = reviews_test['Label'].tolist()\n",
    "x_test_review = reviews_test['review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bag of words tfidf \n",
    "# #It converts text to word frequency vectors\n",
    "# #word-level\n",
    "\n",
    "# tfidfvec = TfidfVectorizer(token_pattern=r'\\w{1,}', max_features=1000, stop_words='english')\n",
    "# tfidfvec.fit(x_train_review)\n",
    "# xtrain_review_tfidf =  tfidfvec.transform(x_train_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtrain_review_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-8eb32c7bffb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_review_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xtrain_review_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "print(xtrain_review_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #n-gram\n",
    "# tfidf_ngram = TfidfVectorizer(token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=1000, stop_words='english')\n",
    "# xtrain_rev_ngram =  tfidf_ngram.fit_transform(x_train_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the data set into a training and test set using countvectorizer\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(countvect, countl, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #naive bayes  count vector as split of test and training\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# Multiclassifier = MultinomialNB()\n",
    "# Multiclassifier.fit(X_train, y_train)\n",
    "# y_pred = Multiclassifier.predict(X_test)\n",
    "\n",
    "# # .3f gives us 3 decimal points\n",
    "# print('Accuracy Score on Training data: {0:.3f}'.format(Multiclassifier.score(X_train, y_train)))\n",
    "# print('Accuracy Score on Testing data: {0:.3f}'.format(Multiclassifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_train_review, y_train_label, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train2)\n",
    "testing_data = count_vector.transform(X_test2)\n",
    "\n",
    "# Instantiate our model\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# Fit our model to the training data\n",
    "naive_bayes.fit(training_data, y_train2)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "\n",
    "# Score our model\n",
    "\n",
    "print('Accuracy score: ', format(accuracy_score(y_test2, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test2, predictions)))\n",
    "print('Recall score: ', format(recall_score(y_test2, predictions)))\n",
    "print('F1 score: ', format(f1_score(y_test2, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram - bgram naive bayes\n",
    "bigram_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        binary=True,\n",
    "        ngram_range=(1, 2)\n",
    "    ),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "bigram_naive_bayes.fit(X_train2, y_train2)\n",
    "\n",
    "print(f'Accuracy: {bigram_naive_bayes.score(X_test2, y_test2)} \\n')\n",
    "print(classification_report(y_test2, bigram_naive_bayes.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram - bgram naive bayes with tfidf\n",
    "nb_bigram_tfidf = make_pipeline(\n",
    "    TfidfVectorizer(ngram_range=(1, 2)),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "nb_bigram_tfidf.fit(X_train2, y_train2)\n",
    "\n",
    "print(f'Accuracy: {nb_bigram_tfidf.score(X_test2, y_test2)} \\n')\n",
    "print(classification_report(y_test2, nb_bigram_tfidf.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram - logistic regression with bigram\n",
    "LogRegbigram = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1,2)\n",
    "    ),\n",
    "    LogReg()\n",
    ")\n",
    "\n",
    "LogRegbigram.fit(X_train2, y_train2)\n",
    "\n",
    "print(f'Accuracy: {LogRegbigram.score(X_test2, y_test2)} \\n')\n",
    "print(classification_report(y_test2, LogRegbigram.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram - logistic regression with tfidf and bigram\n",
    "bigram_tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1,2)\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogReg()\n",
    ")\n",
    "\n",
    "bigram_tfidf_logistic_regression.fit(X_train2, y_train2)\n",
    "\n",
    "print(f'Accuracy: {bigram_tfidf_logistic_regression.score(X_test2, y_test2)} \\n')\n",
    "print(classification_report(y_test2, bigram_tfidf_logistic_regression.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm bigram\n",
    "bigram_svm = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        binary=True,\n",
    "        ngram_range=(1, 2)\n",
    "    ),\n",
    "    SGDClassifier()\n",
    ")\n",
    "\n",
    "bigram_svm.fit(X_train2, y_train2)\n",
    "\n",
    "print(f'Accuracy: {bigram_svm.score(X_test2, y_test2)} \\n')\n",
    "print(classification_report(y_test2, bigram_svm.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm bigram with tfidf\n",
    "bigram_svm_tfidf = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    SGDClassifier()\n",
    ")\n",
    "\n",
    "bigram_svm_tfidf.fit(X_train2, y_train2)\n",
    "\n",
    "print(f'Accuracy: {bigram_svm_tfidf.score(X_test2, y_test2)} \\n')\n",
    "print(classification_report(y_test2, bigram_svm_tfidf.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_training(training_model,vectorizer_2n):\n",
    "    if training_model == 'LR':\n",
    "        \n",
    "        if vectorizer_2n == 'BOW':\n",
    "            print (\"Training Logistic regression model using bag of words\")\n",
    "            model_LR_BOW = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LogReg()),])\n",
    "            return model_LR_BOW\n",
    "           \n",
    "        elif vectorizer_2n == 'TFIDF':\n",
    "            print (\"Training Logistic regression model using TFIDF\")\n",
    "            model_LR_TFIDF = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogReg()),])\n",
    "            return model_LR_TFIDF\n",
    "    \n",
    "    elif training_model == 'SVM':\n",
    "        print (\"Training SVM model using bag of words\")\n",
    "        if vectorizer_2n == 'BOW':\n",
    "            model_SVM_BOW = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', SGDClassifier()),])\n",
    "            return model_SVM_BOW\n",
    "                        \n",
    "        elif vectorizer_2n == 'TFIDF':\n",
    "            print (\"Training SVM model using TFIDF\")\n",
    "            model_SVM_TFIDF = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier()),])\n",
    "            return model_SVM_TFIDF\n",
    "    \n",
    "    elif training_model == 'RF':\n",
    "        \n",
    "        if vectorizer_2n == 'BOW':\n",
    "            print (\"Training RF model using bag of words\")\n",
    "            model_SVM_BOW = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', RandomForestClassifer()),])\n",
    "            return model_SVM_BOW\n",
    "                        \n",
    "        elif vectorizer_2n == 'TFIDF':\n",
    "            print (\"Training RF model using TFIDF\")\n",
    "            model_SVM_TFIDF = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', RandomForestClassifer()),])\n",
    "            return model_SVM_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "def model_fitting_in_different_dataset():\n",
    "    training_model = ['LR','SVM', 'NB', 'RF']\n",
    "    vectorizer_2n = ['BOW','TFIDF']\n",
    "    for i in training_model:\n",
    "        for j in vectorizer_2n:\n",
    "            print (i, \"and\",j)\n",
    "            fit_model3 = model_training(i,j).fit(X_train2, y_train2)\n",
    "            predicted3 = fit_model3.predict(X_test2)\n",
    "            accuracy3 = np.mean(predicted3 == y_test2)\n",
    "            scores10 = cross_val_score(fit_model3, X_train2, y_train2, cv=10)\n",
    "            print (\"Accuracy on testing dataset is\",accuracy3)\n",
    "            print(\"Accuracy on training dataset is : %0.3f\" % (scores10.mean()))\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logstic Regression + Count VEctorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fitting_in_different_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogReg()),])\n",
    "model =model.fit(X_train2, y_train2)\n",
    "print(\"Cross Validation for Logistic regression on Count Vectorizer and TFID Transformer\")\n",
    "cross_val_score(model, X_train2, y_train2, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsvm = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier()),])\n",
    "modelsvm =modelsvm.fit(X_train2, y_train2)\n",
    "print(\"Cross Validation for SVM on Count Vectorizer and TFID Transformer\")\n",
    "cross_val_score(modelsvm, X_train2, y_train2, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnb = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])\n",
    "model =model.fit(X_train2, y_train2)\n",
    "print(\"Cross Validation for Naive Bayes on Count Vectorizer and TFID Transformer\")\n",
    "cross_val_score(modelnb, X_train2, y_train2, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to find the best parameters\n",
    "parameters = {\"tfidf__min_df\": {2, 5}, \"ngram_range__tfidf\": [(1, 1), (1, 2)], \"n_estimators__clf\" : [50, 100, 200], \"max_depth__clf\": [100, 1000]}\n",
    "\n",
    "pipeline_rf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "rfgridsearch = GridSearchCV(pipeline_rf, parameters, cv=5)\n",
    "rfgridsearch.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = rfgridsearch.predict(X_test2)\n",
    "\n",
    "print('Accuracy score: ', format(accuracy_score(y_test2, y_pred)))\n",
    "print('Precision score: ', format(precision_score(y_test2, y_pred)))\n",
    "print('Recall score: ', format(recall_score(y_test2, y_pred)))\n",
    "print('F1 score: ', format(f1_score(y_test2, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-215180e7b09f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                      ('clf', LogisticRegression())])\n\u001b[0;32m      6\u001b[0m \u001b[0mlrgridsearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mlrgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlrgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1549\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         epsilon, sample_weight)\n\u001b[0m\u001b[0;32m    922\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#we have to find the best parameters\n",
    "parameters = {\"tfidf__min_df\": [2, 5], \"tfidf__ngram_range\": [(1, 1), (1, 2)], \"clf__C\" : [0.1, 1, 10]}\n",
    "\n",
    "pipeline_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression())])\n",
    "lrgridsearch = GridSearchCV(pipeline_lr, parameters, cv=5)\n",
    "lrgridsearch.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = lrgridsearch.predict(X_test2)\n",
    "\n",
    "print('Accuracy score: ', format(accuracy_score(y_test2, y_pred)))\n",
    "print('Precision score: ', format(precision_score(y_test2, y_pred)))\n",
    "print('Recall score: ', format(recall_score(y_test2, y_pred)))\n",
    "print('F1 score: ', format(f1_score(y_test2, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randata = vectorizer.fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndtest = vectorizer.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndomforest = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndomforest.fit(randata, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforestpredict = rndomforest.predict(rndtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        print('Accuracy score for Random Forest:' , format(accuracy_score(y_test2, randomforestpredict)))\n",
    "        print('Precision score Random Forest :' , format(precision_score(y_test2, randomforestpredict)))\n",
    "        print('Recall score Random Forest :', format(recall_score(y_test2, randomforestpredict)))\n",
    "        print('F1 score Random Forest :', format(f1_score(y_test2, randomforestpredict)))\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random classifier\n",
    "\n",
    "randomforest2 = RandomForestClassifier(criterion = 'entropy')\n",
    "randomforest2.fit(training_data, y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training acc:\", randomforest2.score(training_data, y_train2), \"\\nValidation acc:\",\n",
    "      randomforest2.score(testing_data, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to find the best parameters\n",
    "rfparameters = {\"n_estimators\" : [10, 20, 50, 100],\n",
    "              \"max_depth\": [100, 1000, 10000],\n",
    "              \"min_samples_split\": [5, 10, 50, 100, 500],\n",
    "              \"min_samples_leaf\": [10, 100, 1000],\n",
    "              \"max_leaf_nodes\": [None, 10, 100, 1000],\n",
    "              }\n",
    "rfgridsearch = GridSearchCV(randomforest2, rfparameters)\n",
    "rfgridsearch.fit(training_data, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying best parameters of random forest classifier \n",
    "rfgridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after displaying we will take the best parameters into consideration\n",
    "ran_forest_best = rfgridsearch.best_estimator_\n",
    "ran_forest_best.fit(training_data, y_train2)\n",
    "print(\"Training accuracy for the best parameters is :\", ran_forest_best.score(training_data, y_train2), \"\\Testing accuracy for the best parameters is: \",\n",
    "      ran_forest_best.score(testing_data, y_test2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
